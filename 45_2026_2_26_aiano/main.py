import os
from typing import List, Optional, Literal
from pydantic import BaseModel, Field
from openai import OpenAI
import dotenv
dotenv.load_dotenv()

client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY_LLUMINAI", "mock-key"))

# --- ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®šç¾© ---

class Document(BaseModel):
    id: str
    content: str
    metadata: dict = {}

class Span(BaseModel):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆç®‡æ‰€"""
    doc_id: str
    start: int
    end: int
    text: str

class AnnotationContext(BaseModel):
    """ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä½œæ¥­ã®ç¾åœ¨ã®çŠ¶æ…‹"""
    query: str
    selected_spans: List[Span] = []
    documents: List[Document] = []

# --- AIANO Blockã®åŸºåº•ã‚¯ãƒ©ã‚¹ ---

class BaseBlock:
    def __init__(self, name: str, prompt_template: str = ""):
        self.name = name
        self.prompt_template = prompt_template

    def process(self, context: AnnotationContext) -> str:
        raise NotImplementedError

# --- å„ãƒ¢ãƒ¼ãƒ‰ã®å®Ÿè£… ---

class AISoloBlock(BaseBlock):
    """
    Mode (ii) AI Solo: ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã«åŸºã¥ã„ã¦è‡ªå‹•ç”Ÿæˆ
    ä¾‹ï¼šãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰è³ªå•(Query)ã‚’ç”Ÿæˆã™ã‚‹
    """
    def process(self, context: AnnotationContext) -> str:
        # æ–‡è„ˆã¨ã—ã¦å…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å†…å®¹ã‚’çµåˆï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        full_text = "\n".join([d.content for d in context.documents])
        
        prompt = self.prompt_template.format(context=full_text)
        
        print(f"ğŸ¤– [AI Solo] Generating for {self.name}...")
        # å®Ÿéš›ã¯ã“ã“ã§APIã‚³ãƒ¼ãƒ«
        # response = client.chat.completions.create(...)
        return f"Generated Content based on {len(full_text)} chars doc."

class CollaborativeBlock(BaseBlock):
    """
    Mode (iii) Human-AI Collaborative: 
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›(Query) + ãƒã‚¤ãƒ©ã‚¤ãƒˆ(Spans) + ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ç”Ÿæˆ
    """
    def process(self, context: AnnotationContext) -> str:
        # ãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚ŒãŸæ ¹æ‹ ã®ã¿ã‚’æŠ½å‡º
        evidence_text = "\n".join([f"- {span.text}" for span in context.selected_spans])
        
        if not evidence_text:
            return "âš ï¸ æ ¹æ‹ ç®‡æ‰€ãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ§‹ç¯‰
        system_msg = "ã‚ãªãŸã¯RAGãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚æä¾›ã•ã‚ŒãŸæ ¹æ‹ ã«åŸºã¥ã„ã¦ã€è³ªå•ã«å¯¾ã™ã‚‹æ­£ç¢ºãªå›ç­”ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
        user_msg = self.prompt_template.format(
            query=context.query,
            evidence=evidence_text
        )
        
        print(f"ğŸ¤ [Collaborative] Generating answer from {len(context.selected_spans)} spans...")
        
        # ãƒ¢ãƒƒã‚¯ã§ã¯ãªãå®Ÿéš›ã«å‹•ãã‚³ãƒ¼ãƒ‰ä¾‹ï¼ˆAPIã‚­ãƒ¼ãŒã‚ã‚Œã°å‹•ä½œï¼‰
        try:
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": system_msg},
                    {"role": "user", "content": user_msg}
                ],
                temperature=0.7
            )
            return response.choices[0].message.content
        except Exception as e:
            return f"Error: {e}"

# --- å®Ÿè¡Œãƒ‡ãƒ¢ ---

def run_aiano_demo():
    # 1. ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®æº–å‚™
    docs = [
        Document(id="doc1", content="AIANOã¯2026å¹´ã«ç™ºè¡¨ã•ã‚ŒãŸã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚"),
        Document(id="doc2", content="ã“ã®ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã†ã¨ã€RAGã®ãƒ‡ãƒ¼ã‚¿ä½œæˆé€Ÿåº¦ãŒç´„2å€ã«ãªã‚Šã¾ã™ã€‚"),
        Document(id="doc3", content="Reactã¨FastAPIã§æ§‹ç¯‰ã•ã‚Œã¦ã„ã¾ã™ã€‚")
    ]

    # 2. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆè³ªå•å…¥åŠ› + ãƒã‚¤ãƒ©ã‚¤ãƒˆï¼‰
    context = AnnotationContext(
        query="AIANOã‚’ä½¿ã†ãƒ¡ãƒªãƒƒãƒˆã¯ä½•ã§ã™ã‹ï¼Ÿ",
        documents=docs,
        selected_spans=[
            Span(doc_id="doc2", start=0, end=10, text="RAGã®ãƒ‡ãƒ¼ã‚¿ä½œæˆé€Ÿåº¦ãŒç´„2å€ã«ãªã‚Šã¾ã™ã€‚")
        ]
    )

    # 3. Collaborative Blockã®è¨­å®š
    answer_block = CollaborativeBlock(
        name="Answer Generation",
        prompt_template="""
        è³ªå•: {query}
        
        ä»¥ä¸‹ã®æ ¹æ‹ ã¨ãªã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„:
        {evidence}
        
        å›ç­”:
        """
    )

    # 4. ç”Ÿæˆå®Ÿè¡Œ
    result = answer_block.process(context)
    
    print("-" * 20)
    print(f"Q: {context.query}")
    print(f"Evidence: {[s.text for s in context.selected_spans]}")
    print(f"A (AI Generated): {result}")
    print("-" * 20)

if __name__ == "__main__":
    run_aiano_demo()