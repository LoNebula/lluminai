import torch
import requests
from PIL import Image, ImageDraw
from io import BytesIO
from colpali_engine.models import ColPali, ColPaliProcessor
from colpali_engine.utils.torch_utils import get_torch_device

def get_image_from_url_or_create_dummy(url, desc):
    """ç”»åƒã‚’DLã—ã€å¤±æ•—ã—ãŸã‚‰ãƒ€ãƒŸãƒ¼ç”»åƒã‚’ç”Ÿæˆã™ã‚‹å®‰å…¨è£…ç½®"""
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    try:
        print(f"   Downloading: {desc}...", end="")
        response = requests.get(url, headers=headers, timeout=5)
        response.raise_for_status()
        img = Image.open(BytesIO(response.content)).convert("RGB")
        print(" OK!")
        return img
    except Exception as e:
        print(f" Failed ({e}). Creating dummy image instead.")
        # ç™½ç´™ã®ç”»åƒã‚’ä½œæˆ
        img = Image.new('RGB', (448, 448), color=(255, 255, 255))
        return img

def main():
    print("ğŸš€ ç’°å¢ƒè¨­å®šã‚’ç¢ºèªä¸­...")
    device = get_torch_device("auto")
    print(f"   Device: {device}")

    # 1. ãƒ¢ãƒ‡ãƒ«ã¨ãƒ—ãƒ­ã‚»ãƒƒã‚µã®ãƒ­ãƒ¼ãƒ‰
    model_name = "vidore/colpali-v1.2"
    
    print(f"ğŸ“¥ ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {model_name} ...")
    model = ColPali.from_pretrained(
        model_name,
        # ãƒ¡ãƒ¢ãƒªç¯€ç´„ã®ãŸã‚ bfloat16 ã‚’å¼·åˆ¶ä½¿ç”¨ (CPUã§ã‚‚ãƒ­ãƒ¼ãƒ‰å¯èƒ½ã«ã™ã‚‹)
        dtype=torch.bfloat16, 
        device_map=device,
    ).eval()

    processor = ColPaliProcessor.from_pretrained(model_name)
    print("âœ… ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å®Œäº†")

    # 2. ãƒ†ã‚¹ãƒˆç”¨ç”»åƒã®æº–å‚™ (Githubã®å®‰å®šã—ãŸç”»åƒ + äºˆå‚™)
    # ColPaliã®ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ï¼ˆæ–‡å­—ã‚’å«ã‚“ã æ–‡æ›¸ã¨ã—ã¦åˆ©ç”¨ï¼‰
    # COCOãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®çŒ«ï¼ˆè‡ªç„¶ç”»åƒã¨ã—ã¦åˆ©ç”¨ï¼‰
    image_sources = [
        {"url": "https://raw.githubusercontent.com/illuin-tech/colpali/main/assets/colpali_architecture.png", "desc": "Document(ColPali Paper)"},
        {"url": "http://images.cocodataset.org/val2017/000000039769.jpg", "desc": "Cat Image"}
    ]
    
    images = []
    valid_descs = []
    
    print("\nğŸ–¼ï¸ ç”»åƒã‚’æº–å‚™ä¸­...")
    for source in image_sources:
        img = get_image_from_url_or_create_dummy(source["url"], source["desc"])
        images.append(img)
        valid_descs.append(source["desc"])

    # 3. ã‚¯ã‚¨ãƒªã®æº–å‚™
    queries = [
        "What is ColPali?",            # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ç”¨
        "Is there a cat?",             # çŒ«ç”»åƒç”¨
        "Show me the architecture."    # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å›³ç”¨
    ]

    # 4. å‰å‡¦ç†
    print("\nâš™ï¸ Embeddingç”Ÿæˆã¨ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°è¨ˆç®—ä¸­... (CPUã®å ´åˆã€30ç§’ã€œ1åˆ†ã»ã©ã‹ã‹ã‚Šã¾ã™)")
    
    # ç”»åƒã®å‡¦ç†
    batch_images = processor.process_images(images).to(device)
    # ã‚¯ã‚¨ãƒªã®å‡¦ç†
    batch_queries = processor.process_queries(queries).to(device)

    # 5. æ¨è«– & ã‚¹ã‚³ã‚¢è¨ˆç®—
    with torch.no_grad():
        image_embeddings = model(**batch_images)
        query_embeddings = model(**batch_queries)

    # ColPaliã®ã‚¹ã‚³ã‚¢è¨ˆç®—
    scores = processor.score_multi_vector(query_embeddings, image_embeddings)

    # 6. çµæœã®è¡¨ç¤º
    print("\nğŸ“Š --- æ¤œç´¢çµæœ (é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢) ---")
    for i, query in enumerate(queries):
        print(f"\nğŸ” Query: '{query}'")
        for j, desc in enumerate(valid_descs):
            score = scores[i, j].item()
            print(f"   ğŸ“„ vs {desc}: Score = {score:.4f}")
            
            # ç›¸å¯¾æ¯”è¼ƒã§åˆ¤å®š
            # ä»–ã®ç”»åƒã‚ˆã‚Šã‚¹ã‚³ã‚¢ãŒé¡•è‘—ã«é«˜ã‘ã‚Œã°ãƒãƒƒãƒã¨ã¿ãªã™
            if score == max(scores[i]):
                print("      ğŸ‘‰ â˜… Top Match!")

if __name__ == "__main__":
    main()