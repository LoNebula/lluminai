import os
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.prompts import ChatPromptTemplate
from dotenv import load_dotenv
from src.state import AgentState

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

key = os.getenv("OPENAI_API_KEY_LLUMINAI")

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
llm = ChatOpenAI(model="gpt-5.2", temperature=0.7, api_key=key)
search_tool = TavilySearchResults(max_results=3)

def researcher_node(state: AgentState):
    """Webæ¤œç´¢ã‚’è¡Œã„ã€æƒ…å ±ã‚’åé›†ã™ã‚‹"""
    topic = state["topic"]
    print(f"\nğŸ•µï¸  Researcher: ã€Œ{topic}ã€ã«ã¤ã„ã¦èª¿æŸ»ã—ã¦ã„ã¾ã™...")
    
    # Tavilyã§æ¤œç´¢
    try:
        search_results = search_tool.invoke(topic)
        # çµæœã‚’è¦‹ã‚„ã™ãæ•´å½¢
        context_text = "\n".join(
            [f"- {res['content']} (Source: {res['url']})" for res in search_results]
        )
    except Exception as e:
        context_text = f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        
    return {"research_data": context_text}

def writer_node(state: AgentState):
    """èª¿æŸ»çµæœã¨æŒ‡æ‘˜ã‚’ã‚‚ã¨ã«è¨˜äº‹ã‚’æ›¸ã"""
    print("\nğŸ–Šï¸  Writer: åŸ·ç­†ä¸­...")
    
    topic = state["topic"]
    research_data = state.get("research_data", "ãƒ‡ãƒ¼ã‚¿ãªã—")
    feedback = state.get("review_comment", "ãªã—")
    current_count = state.get("revision_count", 0)

    prompt_text = f"""
    ã‚ãªãŸã¯Zennãªã©ã®ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°ã§æ´»èºã™ã‚‹æŠ€è¡“ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
    ä»¥ä¸‹ã®æƒ…å ±ã‚’å…ƒã«ã€ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢å‘ã‘ã®æŠ€è¡“è¨˜äº‹ã‚’Markdownå½¢å¼ã§åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚

    ã€ãƒ†ãƒ¼ãƒã€‘: {topic}
    ã€èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã€‘: {research_data}
    ã€æŸ»èª­è€…ã‹ã‚‰ã®æŒ‡æ‘˜ã€‘: {feedback} (â€»ã€Œãªã—ã€ã®å ´åˆã¯åˆå›åŸ·ç­†ã§ã™)

    è¦ä»¶:
    - èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’æ ¹æ‹ ã«ã™ã‚‹ï¼ˆãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ã‚’é¿ã‘ã‚‹ï¼‰
    - ã‚³ãƒ¼ãƒ‰ã‚¹ãƒ‹ãƒšãƒƒãƒˆãŒå¿…è¦ãªå ´åˆã¯ã€Pythonç­‰ã®é©åˆ‡ãªã‚³ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹
    - æŸ»èª­è€…ã‹ã‚‰ã®æŒ‡æ‘˜ãŒã‚ã‚‹å ´åˆã¯ã€å¿…ãšä¿®æ­£ã—ã¦åæ˜ ã™ã‚‹
    """
    
    messages = [("system", prompt_text), ("human", "è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚")]
    response = llm.invoke(messages)
    
    return {
        "draft": response.content,
        "revision_count": current_count + 1
    }

def reviewer_node(state: AgentState):
    """è¨˜äº‹ã‚’æŸ»èª­ã™ã‚‹"""
    print("\nğŸ§ Reviewer: æŸ»èª­ä¸­...")
    
    draft = state["draft"]
    
    prompt_text = f"""
    ã‚ãªãŸã¯å³æ ¼ãªæŠ€è¡“ãƒ¡ãƒ‡ã‚£ã‚¢ã®ç·¨é›†é•·ã§ã™ã€‚
    ä»¥ä¸‹ã®è¨˜äº‹ãƒ‰ãƒ©ãƒ•ãƒˆã‚’æ‰¹åˆ¤çš„ã«ãƒ¬ãƒ“ãƒ¥ãƒ¼ã—ã¦ãã ã•ã„ã€‚

    ã€ãƒã‚§ãƒƒã‚¯é …ç›®ã€‘
    1. æŠ€è¡“çš„ãªèª¤ã‚Šã¯ãªã„ã‹ï¼Ÿ
    2. èª­è€…ã«ã¨ã£ã¦æœ‰ç›Šãªå…·ä½“æ€§ãŒã‚ã‚‹ã‹ï¼Ÿ
    3. æ§‹æˆã¯è«–ç†çš„ã‹ï¼Ÿ

    ã€å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    - å•é¡ŒãŒãªã„å ´åˆ: æ–‡é ­ã«ã€ŒACCEPTã€ã¨è¨˜è¿°ã—ã€è©•ä¾¡ã‚³ãƒ¡ãƒ³ãƒˆã‚’ç¶šã‘ã‚‹ã€‚
    - ä¿®æ­£ãŒå¿…è¦ãªå ´åˆ: å…·ä½“çš„ãªä¿®æ­£æŒ‡ç¤ºï¼ˆCritiqueï¼‰ã®ã¿ã‚’è¨˜è¿°ã™ã‚‹ã€‚

    ã€å¯¾è±¡ãƒ‰ãƒ©ãƒ•ãƒˆã€‘:
    {draft}
    """
    
    messages = [("system", prompt_text), ("human", "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")]
    response = llm.invoke(messages)
    
    return {"review_comment": response.content}
