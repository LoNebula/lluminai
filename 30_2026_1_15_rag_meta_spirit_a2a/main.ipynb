{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f69074c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\n",
      "åˆæœŸå…¥åŠ›: [10, 20, 5, 6, 7]\n",
      "åˆæœŸãƒã‚¹ã‚¯: [0, 0, 1, 1, 1] (0=Text, 1=Speech)\n",
      "\n",
      "--- Spirit LM æ¨è«–ãƒ«ãƒ¼ãƒ— ---\n",
      "--- ç”Ÿæˆé–‹å§‹ (åˆæœŸå…¥åŠ›é•·: 5) ---\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:355\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:254\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:283\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:126\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:368\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:572\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:230\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:80\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:208\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:539\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:126\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:368\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:766\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:928\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:1\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:463\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:442\n",
      "ç”Ÿæˆ: ğŸ“ Text | ID:607\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:286\n",
      "ç”Ÿæˆ: ğŸµ Speech | Unit:364\n",
      "\n",
      "âœ… ç”Ÿæˆçµ‚äº†\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# === 1. è¨­å®š (Config) ===\n",
    "CONFIG = {\n",
    "    \"text_vocab_size\": 1000,    # ãƒ†ã‚­ã‚¹ãƒˆã®èªå½™æ•° (ç°¡æ˜“ç‰ˆ)\n",
    "    \"speech_vocab_size\": 500,   # éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³(HuBERT)ã®ç¨®é¡æ•°\n",
    "    \"dim\": 256,                 # åŸ‹ã‚è¾¼ã¿æ¬¡å…ƒ\n",
    "    \"layers\": 2,                # Transformerå±¤æ•°\n",
    "    \"heads\": 4,                 # Attentionãƒ˜ãƒƒãƒ‰æ•°\n",
    "    \"max_len\": 50               # ç”Ÿæˆã™ã‚‹æœ€å¤§é•·\n",
    "}\n",
    "\n",
    "# === 2. ãƒ¢ãƒ‡ãƒ«å®šç¾© (The Spirit LM) ===\n",
    "class RunnableSpiritLM(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        \n",
    "        # A. åŸ‹ã‚è¾¼ã¿å±¤ (Text & Speech)\n",
    "        self.text_emb = nn.Embedding(cfg[\"text_vocab_size\"], cfg[\"dim\"])\n",
    "        self.speech_emb = nn.Embedding(cfg[\"speech_vocab_size\"], cfg[\"dim\"])\n",
    "        \n",
    "        # B. ä½ç½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚° (ç°¡æ˜“çš„)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, 1024, cfg[\"dim\"]))\n",
    "        \n",
    "        # C. Backbone (Llama 2ç›¸å½“ã®Transformer)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=cfg[\"dim\"], \n",
    "            nhead=cfg[\"heads\"], \n",
    "            dim_feedforward=cfg[\"dim\"]*4,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=cfg[\"layers\"])\n",
    "        \n",
    "        # D. å‡ºåŠ›å±¤ (ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã‚’çµåˆã—ãŸå…¨èªå½™ç©ºé–“ã¸å°„å½±)\n",
    "        # å‡ºåŠ›æ¬¡å…ƒ = ãƒ†ã‚­ã‚¹ãƒˆèªå½™ + éŸ³å£°èªå½™\n",
    "        self.total_vocab = cfg[\"text_vocab_size\"] + cfg[\"speech_vocab_size\"]\n",
    "        self.head = nn.Linear(cfg[\"dim\"], self.total_vocab)\n",
    "\n",
    "    def forward(self, input_ids, modality_mask):\n",
    "        \"\"\"\n",
    "        input_ids: [Batch, Seq_Len] (ãƒˆãƒ¼ã‚¯ãƒ³ID)\n",
    "        modality_mask: [Batch, Seq_Len] (0=Text, 1=Speech)\n",
    "        \"\"\"\n",
    "        B, T = input_ids.shape\n",
    "        \n",
    "        # 1. ãƒ¢ãƒ€ãƒªãƒ†ã‚£ã«å¿œã˜ãŸEmbeddingã®é¸æŠ (ã“ã“ãŒSpirit LMã®è‚ï¼)\n",
    "        # maskãŒ0ãªã‚‰text_emb, 1ãªã‚‰speech_embã‚’ä½¿ã†\n",
    "        # â€» input_idsã¯ãã‚Œãã‚Œã®èªå½™ã‚µã‚¤ã‚ºå†…ã«åã¾ã£ã¦ã„ã‚‹å‰æ\n",
    "        \n",
    "        # ãƒ†ã‚­ã‚¹ãƒˆç”¨åŸ‹ã‚è¾¼ã¿\n",
    "        t_emb = self.text_emb(input_ids.clamp(0, self.cfg[\"text_vocab_size\"]-1))\n",
    "        # éŸ³å£°ç”¨åŸ‹ã‚è¾¼ã¿\n",
    "        s_emb = self.speech_emb(input_ids.clamp(0, self.cfg[\"speech_vocab_size\"]-1))\n",
    "        \n",
    "        # ãƒã‚¹ã‚¯ã‚’ä½¿ã£ã¦ãƒ–ãƒ¬ãƒ³ãƒ‰ (ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆ)\n",
    "        mask_expanded = modality_mask.unsqueeze(-1).float() # [B, T, 1]\n",
    "        x = t_emb * (1 - mask_expanded) + s_emb * mask_expanded\n",
    "        \n",
    "        # 2. ä½ç½®æƒ…å ±ã‚’åŠ ç®—\n",
    "        x = x + self.pos_emb[:, :T, :]\n",
    "        \n",
    "        # 3. Transformerå‡¦ç†\n",
    "        x = self.transformer(x)\n",
    "        \n",
    "        # 4. æ¬¡ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬\n",
    "        logits = self.head(x) # [B, T, Total_Vocab]\n",
    "        return logits\n",
    "\n",
    "# === 3. ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ (Generation Loop) ===\n",
    "def generate(model, start_tokens, start_masks, max_new_tokens=20):\n",
    "    model.eval()\n",
    "    \n",
    "    # ç¾åœ¨ã®ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ (List)\n",
    "    curr_ids = start_tokens.tolist()[0]\n",
    "    curr_masks = start_masks.tolist()[0]\n",
    "    \n",
    "    print(f\"--- ç”Ÿæˆé–‹å§‹ (åˆæœŸå…¥åŠ›é•·: {len(curr_ids)}) ---\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_new_tokens):\n",
    "            # ãƒ†ãƒ³ã‚½ãƒ«åŒ–\n",
    "            input_tensor = torch.tensor([curr_ids], dtype=torch.long)\n",
    "            mask_tensor = torch.tensor([curr_masks], dtype=torch.long)\n",
    "            \n",
    "            # æ¨è«–\n",
    "            logits = model(input_tensor, mask_tensor)\n",
    "            \n",
    "            # æœ€å¾Œã®ãƒˆãƒ¼ã‚¯ãƒ³ã®ãƒ­ã‚¸ãƒƒãƒˆã‚’å–å¾—\n",
    "            next_token_logits = logits[0, -1, :]\n",
    "            \n",
    "            # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚° (ä»Šå›ã¯ç°¡æ˜“çš„ã«Argmax)\n",
    "            next_id = torch.argmax(next_token_logits).item()\n",
    "            \n",
    "            # --- åˆ¤å®š: ã“ã‚Œã¯ãƒ†ã‚­ã‚¹ãƒˆã‹éŸ³å£°ã‹ï¼Ÿ ---\n",
    "            # Spirit LMã®å‡ºåŠ›å±¤ã¯ [0 ~ text_vocab] ãŒãƒ†ã‚­ã‚¹ãƒˆ\n",
    "            # [text_vocab ~ total_vocab] ãŒéŸ³å£° ã¨ãƒãƒƒãƒ”ãƒ³ã‚°ã•ã‚Œã¦ã„ã‚‹ã¨ä»®å®š\n",
    "            \n",
    "            if next_id < CONFIG[\"text_vocab_size\"]:\n",
    "                # ãƒ†ã‚­ã‚¹ãƒˆã¨åˆ¤å®š\n",
    "                modality = 0 \n",
    "                token_type = \"ğŸ“ Text\"\n",
    "                # ãƒˆãƒ¼ã‚¯ãƒ³IDã‚’ãã®ã¾ã¾è¡¨ç¤º\n",
    "                display_val = f\"ID:{next_id}\"\n",
    "            else:\n",
    "                # éŸ³å£°ã¨åˆ¤å®š\n",
    "                modality = 1\n",
    "                token_type = \"ğŸµ Speech\"\n",
    "                # éŸ³å£°IDã«æˆ»ã™ (Global ID -> Local Speech ID)\n",
    "                speech_id = next_id - CONFIG[\"text_vocab_size\"]\n",
    "                display_val = f\"Unit:{speech_id}\"\n",
    "            \n",
    "            print(f\"ç”Ÿæˆ: {token_type} | {display_val}\")\n",
    "            \n",
    "            # ã‚·ãƒ¼ã‚±ãƒ³ã‚¹ã«è¿½åŠ ï¼ˆè‡ªå·±å›å¸°ï¼‰\n",
    "            # æ¬¡ã®å…¥åŠ›ã®ãŸã‚ã«ã€Speechã®å ´åˆã¯IDã‚’ãƒ­ãƒ¼ã‚«ãƒ«IDã«ç›´ã—ã¦æ ¼ç´ã™ã‚‹ãªã©\n",
    "            # å®Ÿè£…ã«ã‚ˆã£ã¦ç•°ãªã‚Šã¾ã™ãŒã€ã“ã“ã§ã¯Global IDã®ã¾ã¾æ‰±ã‚ãªã„ã‚ˆã†èª¿æ•´\n",
    "            # â€»ç°¡æ˜“åŒ–ã®ãŸã‚ã€input_idsã«ã¯å¸¸ã«Local IDãŒå…¥ã‚‹ã¨ä»®å®šã—ã¦è£œæ­£\n",
    "            if modality == 1:\n",
    "                input_id_for_next = next_id - CONFIG[\"text_vocab_size\"]\n",
    "            else:\n",
    "                input_id_for_next = next_id\n",
    "                \n",
    "            curr_ids.append(input_id_for_next)\n",
    "            curr_masks.append(modality)\n",
    "            \n",
    "    return curr_ids, curr_masks\n",
    "\n",
    "# === 4. ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œãƒ–ãƒ­ãƒƒã‚¯ ===\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åŒ–\n",
    "    spirit_lm = RunnableSpiritLM(CONFIG)\n",
    "    print(\"âœ… ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰å®Œäº†\")\n",
    "\n",
    "    # --- ãƒ€ãƒŸãƒ¼å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ ---\n",
    "    # ã‚·ãƒãƒ¥ã‚¨ãƒ¼ã‚·ãƒ§ãƒ³: \"Hello\" (Text) ã¨è¨€ã£ãŸå¾Œã« éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³ãŒç¶šãã‚ˆã†ãªçŠ¶æ…‹ã‚’æ¨¡æ“¬\n",
    "    # 0=Text, 1=Speech\n",
    "    \n",
    "    # Text: ID 10, 20 (\"He\", \"llo\")\n",
    "    input_ids = [10, 20] \n",
    "    masks     = [ 0,  0] \n",
    "    \n",
    "    # Speech: ID 5, 6, 7 (éŸ³å£°ãƒˆãƒ¼ã‚¯ãƒ³) ãŒæ··ã–ã£ã¦ãã‚‹ (Interleaved)\n",
    "    input_ids.extend([5, 6, 7])\n",
    "    masks.extend    ([1, 1, 1])\n",
    "    \n",
    "    # Tensorã«å¤‰æ›\n",
    "    input_tensor = torch.tensor([input_ids], dtype=torch.long)\n",
    "    mask_tensor = torch.tensor([masks], dtype=torch.long)\n",
    "    \n",
    "    print(f\"åˆæœŸå…¥åŠ›: {input_ids}\")\n",
    "    print(f\"åˆæœŸãƒã‚¹ã‚¯: {masks} (0=Text, 1=Speech)\")\n",
    "    \n",
    "    # ç”Ÿæˆå®Ÿè¡Œ\n",
    "    print(\"\\n--- Spirit LM æ¨è«–ãƒ«ãƒ¼ãƒ— ---\")\n",
    "    final_ids, final_masks = generate(spirit_lm, input_tensor, mask_tensor)\n",
    "    \n",
    "    print(\"\\nâœ… ç”Ÿæˆçµ‚äº†\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
