# -*- coding: utf-8 -*-
"""rag_excel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17h0V2_gzvTEbz2RWIhT72HzjYBHuVol-
"""

! pip install -q XlsxWriter

# 1. ã‚·ã‚¹ãƒ†ãƒ è¦ä»¶ï¼ˆLibreOfficeã¨æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼‰
!apt-get update
!apt-get install -y libreoffice fonts-ipafont poppler-utils

# 2. Pythonãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆ4bité‡å­åŒ–ç”¨ã®bitsandbytesã‚’å«ã‚€ï¼‰
!pip install -q byaldi transformers accelerate qwen_vl_utils pdf2image bitsandbytes

import xlsxwriter
import os

file_path = 'monthly_sales_report.xlsx'

# ãƒ¯ãƒ¼ã‚¯ãƒ–ãƒƒã‚¯ä½œæˆ
workbook = xlsxwriter.Workbook(file_path)
worksheet = workbook.add_worksheet('Sales Data')

# --- ãƒ‡ãƒ¼ã‚¿ã¨æ›¸å¼ã®æº–å‚™ ---
header_fmt = workbook.add_format({'bold': True, 'bg_color': '#D7E4BC', 'border': 1})
data_fmt = workbook.add_format({'border': 1})
highlight_bad = workbook.add_format({'bg_color': '#FFC7CE', 'font_color': '#9C0006', 'border': 1}) # èµ¤
highlight_good = workbook.add_format({'bg_color': '#C6EFCE', 'font_color': '#006100', 'border': 1}) # ç·‘

# ãƒ‡ãƒ¼ã‚¿ï¼ˆ4æœˆã«åº•ã‚’æ‰“ã¡ã€8æœˆã«å›å¾©ã™ã‚‹ã‚·ãƒŠãƒªã‚ªï¼‰
headers = ['Month', 'Sales (ä¸‡å††)']
data = [
    ['1æœˆ', 400], ['2æœˆ', 350], ['3æœˆ', 300],
    ['4æœˆ', 200], # åº•
    ['5æœˆ', 250], ['6æœˆ', 350], ['7æœˆ', 450],
    ['8æœˆ', 500], # æœ€é«˜
]

# --- ãƒ‡ãƒ¼ã‚¿ã®æ›¸ãè¾¼ã¿ ---
worksheet.write_row('A1', headers, header_fmt)
for row_num, (month, sales) in enumerate(data, start=1):
    fmt = highlight_bad if sales == 200 else (highlight_good if sales == 500 else data_fmt)
    worksheet.write(row_num, 0, month, fmt)
    worksheet.write(row_num, 1, sales, fmt)

# --- ã‚°ãƒ©ãƒ•ã®ä½œæˆï¼ˆPandasã§ã¯èª­ã‚ãªã„ä»£è¡¨æ ¼ï¼‰ ---
chart = workbook.add_chart({'type': 'line'})
chart.add_series({
    'name':       ['Sales Data', 0, 1],
    'categories': ['Sales Data', 1, 0, 8, 0],
    'values':     ['Sales Data', 1, 1, 8, 1],
    'line':       {'color': 'blue', 'width': 2.25},
    'marker':     {'type': 'circle', 'size': 7},
})
chart.set_title ({'name': '2024å¹´ ä¸ŠæœŸå£²ä¸Šæ¨ç§»'})
worksheet.insert_chart('D2', chart)

# --- ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ï¼ˆæ³¨é‡ˆï¼‰ã®è¿½åŠ  ---
# âš ï¸ ã“ã‚ŒãŒé‡è¦ã§ã™ã€‚é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã§ã¯ç„¡è¦–ã•ã‚Œã¾ã™ã€‚
text_options = {
    'width': 250, 'height': 60,
    'font': {'bold': True, 'color': 'red', 'size': 10},
    'line': {'color': 'red', 'width': 2, 'dash_type': 'round_dot'},
    'align': {'vertical': 'middle', 'horizontal': 'center'},
}
worksheet.insert_textbox('H10', 'â€»5æœˆã‹ã‚‰æ–°ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°æ–½ç­–ã‚’é–‹å§‹\nã“ã‚ŒãŒVå­—å›å¾©ã®ä¸»è¦å› ã§ã™', text_options)

workbook.close()
print(f"âœ… ç”Ÿæˆå®Œäº†: {file_path}")

import subprocess
from pdf2image import convert_from_path
import matplotlib.pyplot as plt

def convert_excel_to_rag_ready(excel_path):
    """
    Excelãƒ•ã‚¡ã‚¤ãƒ«ã‚’LibreOfficeã§PDFåŒ–ã—ã€ç”»åƒãƒªã‚¹ãƒˆã¨ã—ã¦è¿”ã™é–¢æ•°
    """
    output_dir = os.path.dirname(os.path.abspath(excel_path))
    filename = os.path.basename(excel_path)
    name_without_ext = os.path.splitext(filename)[0]

    print(f"ğŸ”„ Converting Excel to PDF: {filename}...")

    # LibreOfficeã‚’ãƒ˜ãƒƒãƒ‰ãƒ¬ã‚¹ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œ
    cmd = ["libreoffice", "--headless", "--convert-to", "pdf", "--outdir", output_dir, excel_path]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    except subprocess.CalledProcessError as e:
        print(f"âš ï¸ Conversion failed: {e}"); return None, None

    pdf_path = os.path.join(output_dir, f"{name_without_ext}.pdf")
    if not os.path.exists(pdf_path): return None, None

    print(f"ğŸ“„ PDF Generated: {pdf_path}")
    images = convert_from_path(pdf_path) # ç”»åƒåŒ–
    return pdf_path, images

# --- å®Ÿè¡Œã¨ç¢ºèª ---
if os.path.exists(file_path):
    pdf_path, excel_images = convert_excel_to_rag_ready(file_path)

    # ğŸ‘ï¸ AIãŒè¦‹ã‚‹ä¸–ç•Œã‚’å¯è¦–åŒ–ï¼ˆã‚°ãƒ©ãƒ•ã‚„æ³¨é‡ˆãŒè¦‹ãˆã‚‹ã‹ç¢ºèªï¼ï¼‰
    if excel_images:
        plt.figure(figsize=(10, 6))
        plt.imshow(excel_images[0])
        plt.axis('off')
        plt.title("ã€AI Visionã€‘What the model sees")
        plt.show()

from byaldi import RAGMultiModalModel

# ğŸ§  ColPaliãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ (verbose=0ã§ãƒ­ã‚°æŠ‘åˆ¶)
print("ğŸš€ Loading ColPali model...")
RAG = RAGMultiModalModel.from_pretrained("vidore/colpali-v1.2", verbose=0)

# ğŸ“‘ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆï¼ˆç”»åƒEmbeddingï¼‰
RAG.index(
    input_path=pdf_path,
    index_name="excel_vision_index",
    store_collection_with_index=True,
    overwrite=True
)

# ğŸ” æ¤œç´¢ã‚¯ã‚¨ãƒªï¼šã‚°ãƒ©ãƒ•ã®å½¢çŠ¶ã‚„è¦–è¦šçš„ç‰¹å¾´ã‚’å•ã†
query = "å£²ä¸Šã®æ¨ç§»ã‚°ãƒ©ãƒ•ã‚’è¦‹ã¦ã€æœ€ã‚‚è½ã¡è¾¼ã‚“ã§ã„ã‚‹æœˆã¨ãã®åŸå› ã¨æ€ã‚ã‚Œã‚‹æ³¨é‡ˆã‚’æ•™ãˆã¦"

print(f"ğŸ” Searching for: {query}")
results = RAG.search(query, k=1)

# ãƒ’ãƒƒãƒˆã—ãŸç”»åƒã®å–å¾—
hit_page_idx = results[0].page_num - 1
retrieved_image = excel_images[hit_page_idx]

print(f"âœ… Found relevant sheet (Page {results[0].page_num})")

import gc
import torch

print("ğŸ§¹ Cleaning up VRAM...")

# Retrieverãƒ¢ãƒ‡ãƒ«ã‚’å‰Šé™¤
del RAG
del results

# ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨GPUã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
gc.collect()
torch.cuda.empty_cache()

print("âœ¨ VRAM Cleaned! Ready for Generator.")

from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig
from qwen_vl_utils import process_vision_info

# ğŸ’¾ ãƒ¡ãƒ¢ãƒªä¸è¶³å¯¾ç­–ï¼š4bité‡å­åŒ–ã®è¨­å®š
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
)

model_name = "Qwen/Qwen2-VL-7B-Instruct"
print(f"ğŸš€ Loading VLM (4-bit): {model_name}")

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
# â€» T4 GPUã¯ Flash Attention 2 éå¯¾å¿œã®ãŸã‚æŒ‡å®šã—ã¾ã›ã‚“
model = Qwen2VLForConditionalGeneration.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto",
    torch_dtype=torch.float16,
)
processor = AutoProcessor.from_pretrained(model_name)

# ğŸ“ æ¨è«–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
messages = [
    {
        "role": "user",
        "content": [
            {"type": "image", "image": retrieved_image}, # æ¤œç´¢ã•ã‚ŒãŸExcelç”»åƒ
            {"type": "text", "text": f"ç”»åƒã®å†…å®¹ã«åŸºã¥ãã€æ¬¡ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„: {query}"},
        ],
    }
]

# å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
image_inputs, video_inputs = process_vision_info(messages)
inputs = processor(
    text=[text],
    images=image_inputs,
    videos=video_inputs,
    padding=True,
    return_tensors="pt",
).to("cuda")

print("ğŸ¤– Generating Answer...")

# ç”Ÿæˆå®Ÿè¡Œ
generated_ids = model.generate(**inputs, max_new_tokens=512)
generated_ids_trimmed = [
    out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)
]
output_text = processor.batch_decode(
    generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False
)

print("\n" + "="*30)
print("ğŸ¤– AI Analysis Result")
print("="*30)
print(output_text[0])