import os
from langchain_openai import ChatOpenAI
from langchain_community.tools.tavily_search import TavilySearchResults
from dotenv import load_dotenv
from src.state import AgentState

load_dotenv()

key = os.getenv("OPENAI_API_KEY_LLUMINAI")

llm = ChatOpenAI(model="gpt-5.2", temperature=0.7, api_key=key)
search_tool = TavilySearchResults(max_results=3)

def researcher_node(state: AgentState):
    topic = state["topic"]
    print(f"\nğŸ•µï¸  Researcher: ã€Œ{topic}ã€ã«ã¤ã„ã¦èª¿æŸ»ä¸­...")
    try:
        results = search_tool.invoke(topic)
        context = "\n".join([f"- {r['content']} (url: {r['url']})" for r in results])
    except:
        context = "èª¿æŸ»å¤±æ•—"
    return {"research_data": context}

def writer_node(state: AgentState):
    topic = state["topic"]
    data = state["research_data"]
    reflection = state.get("reflection", "") # åçœæ–‡ã‚’å–å¾—
    count = state.get("revision_count", 0)

    # åˆç¨¿ã‹ä¿®æ­£ç¨¿ã‹ã§è¡¨ç¤ºã‚’å¤‰ãˆã‚‹
    if count == 0:
        print("\nğŸ–Šï¸  Writer: åˆç¨¿ã‚’åŸ·ç­†ä¸­...")
        instruction = "èª¿æŸ»ãƒ‡ãƒ¼ã‚¿ã‚’å…ƒã«ã€æ§‹æˆæ¡ˆã‚’ä½œæˆã—è¨˜äº‹ã‚’åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚"
    else:
        print(f"\nğŸ–Šï¸  Writer: ä¿®æ­£åŸ·ç­†ä¸­ï¼ˆ{count}å›ç›®ï¼‰...")
        # åçœæ–‡ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«æ³¨å…¥ï¼
        instruction = f"""
        ã‚ãªãŸã¯å‰å›ã®åŸ·ç­†ã§æŒ‡æ‘˜ã‚’å—ã‘ã¾ã—ãŸã€‚
        ä»¥ä¸‹ã®ã€ä¿®æ­£è¨ˆç”»ã€‘ã‚’å³å¯†ã«å®ˆã‚Šã€è¨˜äº‹ã‚’å…¨é¢çš„ã«æ›¸ãç›´ã—ã¦ãã ã•ã„ã€‚
        
        ã€ä¿®æ­£è¨ˆç”»ï¼ˆReflectorã‹ã‚‰ã®æŒ‡ç¤ºï¼‰ã€‘:
        {reflection}
        """

    prompt = f"""
    ã‚ãªãŸã¯ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°ã®ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
    ãƒ†ãƒ¼ãƒ: {topic}
    èª¿æŸ»ãƒ‡ãƒ¼ã‚¿: {data}
    
    æŒ‡ç¤º: {instruction}
    
    å‡ºåŠ›ã¯Markdownå½¢å¼ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚
    """
    
    res = llm.invoke(prompt)
    return {"draft": res.content, "revision_count": count + 1}

def reviewer_node(state: AgentState):
    print("\nğŸ§ Reviewer: æŸ»èª­ä¸­...")
    draft = state["draft"]
    
    prompt = f"""
    ã‚ãªãŸã¯å³æ ¼ãªç·¨é›†é•·ã§ã™ã€‚è¨˜äº‹ã‚’è©•ä¾¡ã—ã¦ãã ã•ã„ã€‚
    
    åˆæ ¼åŸºæº–:
    1. æŠ€è¡“çš„ã«æ­£ç¢ºã‹
    2. å…·ä½“çš„ãªã‚³ãƒ¼ãƒ‰ã‚„äº‹ä¾‹ãŒã‚ã‚‹ã‹
    
    åˆæ ¼ãªã‚‰ã€ŒACCEPTã€ã¨ã ã‘å‡ºåŠ›ã€‚
    ä¸åˆæ ¼ãªã‚‰ã€**å…·ä½“çš„ãªæŒ‡æ‘˜äº‹é …ï¼ˆCritiqueï¼‰ã®ã¿**ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    
    è¨˜äº‹:
    {draft}
    """
    res = llm.invoke(prompt)
    return {"review_comment": res.content}

def reflector_node(state: AgentState):
    """ğŸ§  æ–°è¿½åŠ : ãªãœãƒ€ãƒ¡ã ã£ãŸã‹ã‚’åˆ†æã—ã€ä¿®æ­£ãƒ—ãƒ©ãƒ³ã‚’ç«‹ã¦ã‚‹"""
    print("\nğŸ§  Reflector: åçœä¼šä¸­ï¼ˆä¿®æ­£è¨ˆç”»ã®ç­–å®šï¼‰...")
    
    draft = state["draft"]
    critique = state["review_comment"]
    
    prompt = f"""
    ã‚ãªãŸã¯ãƒ©ã‚¤ã‚¿ãƒ¼ã®ãƒ¡ãƒ³ã‚¿ãƒ¼ã§ã™ã€‚
    ä»¥ä¸‹ã®è¨˜äº‹ãƒ‰ãƒ©ãƒ•ãƒˆã«å¯¾ã—ã€æŸ»èª­è€…ã‹ã‚‰æŒ‡æ‘˜ãŒå…¥ã‚Šã¾ã—ãŸã€‚
    
    ã€æŒ‡æ‘˜ã€‘: {critique}
    ã€ãƒ‰ãƒ©ãƒ•ãƒˆã€‘: {draft}
    
    WriterãŒæ¬¡ã«ä½•ã‚’ã™ã¹ãã‹ã€å…·ä½“çš„ãª**ã€Œä¿®æ­£è¨ˆç”»ï¼ˆStep-by-Step Action Planï¼‰ã€**ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
    æ„Ÿæƒ…çš„ãªè¨€è‘‰ã¯ä¸è¦ã§ã™ã€‚ã‚„ã‚‹ã¹ãã‚¿ã‚¹ã‚¯ã‚’3ç‚¹ä»¥å†…ã§ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚
    """
    
    res = llm.invoke(prompt)
    return {"reflection": res.content}