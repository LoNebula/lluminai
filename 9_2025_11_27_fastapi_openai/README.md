# ğŸš€ LLM ãƒ¢ãƒ‡ãƒ«è‡ªå‹•åˆ‡æ›¿ API & UI  
FastAPI Ã— OpenAI Ã— Streamlit

ã“ã®ãƒªãƒã‚¸ãƒˆãƒªã¯ã€**ã‚¿ã‚¹ã‚¯ç¨®åˆ¥ã«å¿œã˜ã¦æœ€é©ãª OpenAI ãƒ¢ãƒ‡ãƒ«ã‚’è‡ªå‹•é¸æŠã—ã¦æ¨è«–ã‚’è¡Œã† API** ã¨ã€ãã® API ã‚’æ“ä½œã™ã‚‹ãŸã‚ã® **Streamlit UI** ã‚’æä¾›ã—ã¾ã™ã€‚

ç›®çš„ã¯ã€ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºã«ãŠã‘ã‚‹  
ã€Œã©ã® LLM ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†ã¹ãã‹å•é¡Œã€ã‚’ API å´ã§å¸åã—ã€  
ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯å˜ã« â€œtaskâ€ ã‚’æŒ‡å®šã™ã‚‹ã ã‘ã§æœ€é©ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•é¸ã°ã‚Œã‚‹ã‚ˆã†ã«ã™ã‚‹ã“ã¨ã§ã™ã€‚

---

# âœ¨ ç‰¹å¾´

- **FastAPI** ã«ã‚ˆã‚‹è»½é‡ï¼†é«˜é€Ÿãªæ¨è«– API
- **ModelSelector** ã«ã‚ˆã‚‹ã‚¿ã‚¹ã‚¯åˆ¥ã® LLM è‡ªå‹•åˆ‡æ›¿  
  ï¼ˆchat / summarize / classify / reasoningï¼‰
- **OpenAI Responses API** ã«å¯¾å¿œï¼ˆæœ€æ–°ä»•æ§˜ï¼‰
- **Streamlit UI** ã§ç›´æ„Ÿçš„ã«æ“ä½œå¯èƒ½
- æ‹¡å¼µã—ã‚„ã™ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆClaude/Geminiå¯¾å¿œã‚‚å®¹æ˜“ï¼‰

---

# ğŸ–¼ï¸ UI ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ

ä»¥ä¸‹ã®ã‚ˆã†ãª UI ã‹ã‚‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã€  
ãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•é¸ã°ã‚Œã¦æ¨è«–çµæœãŒè¿”ã£ã¦ãã¾ã™ã€‚

ï¼ˆâ€» GitHub ã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰å¾Œã€ç”»åƒãƒ‘ã‚¹ã‚’è²¼ã‚Šæ›¿ãˆã¦ãã ã•ã„ï¼‰

![LLM ãƒ¢ãƒ‡ãƒ«è‡ªå‹•åˆ‡æ›¿ UIã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚·ãƒ§ãƒƒãƒˆ](./screenshot.png)

---

# ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```

project/
â”œâ”€â”€ main.py            # FastAPI: APIæœ¬ä½“
â”œâ”€â”€ selector.py        # ãƒ¢ãƒ‡ãƒ«åˆ‡æ›¿ãƒ­ã‚¸ãƒƒã‚¯
â”œâ”€â”€ services.py        # OpenAIå‘¼ã³å‡ºã—ï¼ˆResponses APIï¼‰
â”œâ”€â”€ streamlit_app.py   # Streamlit UI
â”œâ”€â”€ .env               # OPENAI_API_KEY ã‚’æ ¼ç´
â””â”€â”€ README.md

````

---

# ğŸ”§ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

## 1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³

```bash
git clone https://github.com/yourname/yourrepo.git
cd yourrepo
````

## 2. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

ï¼ˆrequirements.txt ãŒç„¡ã„å ´åˆï¼‰

```bash
pip install fastapi uvicorn openai python-dotenv streamlit requests
```

---

# ğŸ”‘ .env ã‚’ä½œæˆ

`OPENAI_API_KEY` ã‚’è¨­å®šã—ã¾ã™ã€‚

```env
OPENAI_API_KEY=sk-********************************
```

---

# ğŸš€ èµ·å‹•æ–¹æ³•

## 1. FastAPIï¼ˆãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ï¼‰

```bash
uvicorn main:app --reload
```

æˆåŠŸã™ã‚‹ã¨ï¼š

```
http://127.0.0.1:8000
```

ã§å‹•ä½œã—ã¾ã™ã€‚

---

## 2. Streamlitï¼ˆãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ï¼‰

åˆ¥ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§ï¼š

```bash
streamlit run streamlit_app.py
```

`http://localhost:8501` ã‚’é–‹ãã¨ UI ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

---

# âš™ï¸ API ä»•æ§˜

### POST `/inference`

FastAPI æœ¬ä½“ã¯ `main.py` ã«å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ã€‚
API ã¯ task ã¨ prompt ã‚’å—ã‘å–ã‚Šã¾ã™ã€‚

ï¼ˆå‚ç…§ï¼š`main.py`ï¼‰

#### ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆJSONï¼‰

```json
{
  "task": "summarize",
  "prompt": "Explain quantum computing in simple terms."
}
```

#### ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆJSONï¼‰

```json
{
  "model_used": "gpt-4o-mini",
  "output": "Quantum computing is..."
}
```

---

# ğŸ§  ãƒ¢ãƒ‡ãƒ«è‡ªå‹•åˆ‡æ›¿ã®ä»•çµ„ã¿

è‡ªå‹•åˆ‡æ›¿ã¯ `selector.py` ã® `ModelSelector` ãŒæ‹…å½“ã—ã¾ã™ã€‚
ï¼ˆå‚ç…§ï¼š`selector.py`ï¼‰

```python
class ModelSelector:
    def choose(self, task: TaskType):
        if task in (TaskType.CLASSIFY, TaskType.SUMMARIZE):
            return "gpt-4o-mini"

        if task == TaskType.CHAT:
            return "gpt-4o"

        if task == TaskType.REASONING:
            return "o1"

        return "gpt-4o"
```

ã‚¿ã‚¹ã‚¯åï¼ˆæ–‡å­—åˆ—â†’Enumï¼‰ãŒå…¥ã‚‹ã ã‘ã§
æœ€é©ãªãƒ¢ãƒ‡ãƒ«ãŒè‡ªå‹•çš„ã«å‰²ã‚Šå½“ã¦ã‚‰ã‚Œã¾ã™ã€‚

---

# ğŸ¤– OpenAI Responses API ã®ä½¿ç”¨

æ¨è«–å‡¦ç†ã¯ `services.py` ã«å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚
ï¼ˆå‚ç…§ï¼š`services.py`ï¼‰

```python
response = client.responses.create(
    model=model,
    input=prompt
)

return {
    "model_used": model,
    "output": response.output_text
}
```

OpenAI ã®æœ€æ–°APIï¼ˆResponses APIï¼‰ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€
`chat.completions` ã‚ˆã‚Šå®‰å®šçš„ã§å°†æ¥ä»•æ§˜ã«ã‚‚å¼·ã„æ§‹æˆã«ãªã£ã¦ã„ã¾ã™ã€‚

---

# ğŸ¨ Streamlit UI

UI ã¯ `streamlit_app.py` ã«å®Ÿè£…ã•ã‚Œã¦ã„ã¾ã™ã€‚
ï¼ˆå‚ç…§ï¼š`streamlit_app.py`ï¼‰

* task ã®ã‚»ãƒ¬ã‚¯ãƒˆãƒœãƒƒã‚¯ã‚¹
* ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›æ¬„
* å®Ÿè¡Œãƒœã‚¿ãƒ³
* è‡ªå‹•é¸ã°ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¤º
* å‡ºåŠ›çµæœã®ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°

ç›´æ„Ÿçš„ã« API ã‚’ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚
