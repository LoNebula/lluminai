{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e9674f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "class GemRagEngine:\n",
    "    def __init__(self, model=None):\n",
    "        \"\"\"\n",
    "        model: エンベディングモデル（encodeメソッドを持つもの）\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.chunks: List[str] = []\n",
    "        self.embeddings: np.ndarray | None = None\n",
    "        self.eigen_scores: np.ndarray | None = None\n",
    "        self.graph: nx.Graph | None = None\n",
    "\n",
    "    def ingest(self, texts: List[str], similarity_threshold: float = 0.5):\n",
    "        \"\"\"\n",
    "        ドキュメントを取り込み、グラフを構築して固有値スコアを計算する\n",
    "        \"\"\"\n",
    "        self.chunks = texts\n",
    "\n",
    "        # 1. エンベディング生成\n",
    "        print(\"Creating embeddings...\")\n",
    "        if self.model:\n",
    "            self.embeddings = np.asarray(self.model.encode(texts))\n",
    "        else:\n",
    "            # モデルがない場合はテスト用にランダムベクトルを使用\n",
    "            np.random.seed(42)\n",
    "            self.embeddings = np.random.rand(len(texts), 384)\n",
    "\n",
    "        # 2. 類似度行列 (Similarity Matrix) の計算\n",
    "        sim_matrix = cosine_similarity(self.embeddings)\n",
    "\n",
    "        # 3. グラフ構築 (Adjacency Matrix)\n",
    "        # 閾値以下のリンクを切り、対角成分(自分自身)を0にする\n",
    "        adj_matrix = (sim_matrix > similarity_threshold).astype(float) * sim_matrix\n",
    "        np.fill_diagonal(adj_matrix, 0.0)\n",
    "\n",
    "        # NetworkXグラフに変換（重みは 'weight' 属性に入る）\n",
    "        self.graph = nx.from_numpy_array(adj_matrix)\n",
    "\n",
    "        # 4. 固有ベクトル中心性 (Eigen-Memory-like Encoding)\n",
    "        print(\"Calculating Eigen-scores...\")\n",
    "        try:\n",
    "            centrality = nx.eigenvector_centrality(\n",
    "                self.graph,\n",
    "                max_iter=1000,\n",
    "                weight=\"weight\",\n",
    "                tol=1e-6,\n",
    "            )\n",
    "            self.eigen_scores = np.array([centrality[i] for i in range(len(texts))])\n",
    "        except nx.PowerIterationFailedConvergence:\n",
    "            print(\"⚠️ 固有値計算が収束しませんでした。次数ベースのスコアを使用します。\")\n",
    "            degrees = np.array([deg for _, deg in self.graph.degree(weight=\"weight\")])\n",
    "            if degrees.max() > 0:\n",
    "                self.eigen_scores = degrees / degrees.max()\n",
    "            else:\n",
    "                self.eigen_scores = np.ones(len(texts))\n",
    "\n",
    "        # スコアの正規化（扱いやすくするため）\n",
    "        if np.max(self.eigen_scores) > 0:\n",
    "            self.eigen_scores = self.eigen_scores / np.max(self.eigen_scores)\n",
    "\n",
    "        print(f\"✅ Indexed {len(texts)} chunks.\")\n",
    "\n",
    "    def search(self, query: str, top_k: int = 3, alpha: float = 0.6) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        alpha: 混合比率 (0.0=EigenScoreのみ, 1.0=類似度のみ)\n",
    "        Score = α * Similarity + (1 - α) * EigenScore\n",
    "        \"\"\"\n",
    "        assert self.embeddings is not None, \"ingest() を先に呼んでください。\"\n",
    "\n",
    "        # クエリのベクトル化\n",
    "        if self.model:\n",
    "            query_vec = self.model.encode([query])[0]\n",
    "        else:\n",
    "            # ★ 修正ポイント: 次元は埋め込みの「特徴次元」だけにする\n",
    "            np.random.seed(0)\n",
    "            query_vec = np.random.rand(self.embeddings.shape[1])\n",
    "\n",
    "        # 1. 類似度スコア (Relevance)\n",
    "        sim_scores = cosine_similarity([query_vec], self.embeddings)[0]\n",
    "\n",
    "        # 2. ハイブリッドスコア計算\n",
    "        final_scores = alpha * sim_scores + (1.0 - alpha) * self.eigen_scores\n",
    "\n",
    "        # 上位取得\n",
    "        top_indices = np.argsort(final_scores)[::-1][:top_k]\n",
    "\n",
    "        results: List[Dict] = []\n",
    "        for idx in top_indices:\n",
    "            results.append({\n",
    "                \"chunk\": self.chunks[idx],\n",
    "                \"score\": float(final_scores[idx]),\n",
    "                \"similarity\": float(sim_scores[idx]),\n",
    "                \"eigen_score\": float(self.eigen_scores[idx]),\n",
    "            })\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7830221b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LoNebula\\miniconda3\\envs\\bs2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings...\n",
      "Calculating Eigen-scores...\n",
      "✅ Indexed 6 chunks.\n",
      "\n",
      "--- 各チャンクの固有値スコア (情報の重要度) ---\n",
      "ID 0: 0.9359 | RAG (Retrieval-Augme...\n",
      "ID 1: 0.9765 | RAGの実装には、一般的にベクトルデータ...\n",
      "ID 2: 0.6383 | ベクトル検索では、コサイン類似度を用いて...\n",
      "ID 3: 0.8743 | GEM-RAGは、グラフ理論を用いてRA...\n",
      "ID 4: 1.0000 | GEM-RAGでは、文書間の関係性から固...\n",
      "ID 5: 0.0000 | 今日の夕飯はカレーライスにしようと思う。...\n",
      "\n",
      "--- 検索テスト: 'GEM-RAGの仕組みは？' ---\n",
      "Score: 0.8887 (Sim: 0.72, Eigen: 1.00)\n",
      "Content: GEM-RAGでは、文書間の関係性から固有値を計算し、重要度とする。\n",
      "--------------------\n",
      "Score: 0.8310 (Sim: 0.77, Eigen: 0.87)\n",
      "Content: GEM-RAGは、グラフ理論を用いてRAGの精度を向上させる手法である。\n",
      "--------------------\n",
      "Score: 0.7155 (Sim: 0.32, Eigen: 0.98)\n",
      "Content: RAGの実装には、一般的にベクトルデータベースが使用される。\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 日本語対応の軽量モデル\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "engine = GemRagEngine(model)\n",
    "\n",
    "# サンプルデータ：RAGに関する断片的な知識\n",
    "docs = [\n",
    "    \"RAG (Retrieval-Augmented Generation) はLLMに外部知識を与える技術だ。\",  # 0: 概要\n",
    "    \"RAGの実装には、一般的にベクトルデータベースが使用される。\",            # 1: 技術詳細\n",
    "    \"ベクトル検索では、コサイン類似度を用いて関連文書を探す。\",              # 2: 技術詳細\n",
    "    \"GEM-RAGは、グラフ理論を用いてRAGの精度を向上させる手法である。\",        # 3: 発展手法\n",
    "    \"GEM-RAGでは、文書間の関係性から固有値を計算し、重要度とする。\",          # 4: 3の詳細\n",
    "    \"今日の夕飯はカレーライスにしようと思う。\",                              # 5: 完全なノイズ\n",
    "]\n",
    "\n",
    "# インデックス作成 (閾値を少し低めに設定してリンクを作りやすくする)\n",
    "engine.ingest(docs, similarity_threshold=0.3)\n",
    "\n",
    "print(\"\\n--- 各チャンクの固有値スコア (情報の重要度) ---\")\n",
    "for i, score in enumerate(engine.eigen_scores):\n",
    "    print(f\"ID {i}: {score:.4f} | {docs[i][:20]}...\")\n",
    "\n",
    "print(\"\\n--- 検索テスト: 'GEM-RAGの仕組みは？' ---\")\n",
    "results = engine.search(\"GEM-RAGの仕組みは？\", top_k=3, alpha=0.4)\n",
    "for res in results:\n",
    "    print(f\"Score: {res['score']:.4f} (Sim: {res['similarity']:.2f}, Eigen: {res['eigen_score']:.2f})\")\n",
    "    print(f\"Content: {res['chunk']}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f25d879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings...\n",
      "Calculating Eigen-scores...\n",
      "✅ Indexed 170 chunks.\n",
      "\n",
      "--- 各チャンクの固有値スコア (情報の重要度) ---\n",
      "ID 0: 0.4701 | # 10,000字程度の物語\n",
      "text_...\n",
      "ID 1: 0.0972 | 最後の配達ルートは、いつもの住宅街。三十...\n",
      "ID 2: 0.6410 | 一軒一軒の表札を見るだけで、そこに住む人...\n",
      "ID 3: 0.1776 | 角を曲がると、古い喫茶店がある。ここの店...\n",
      "ID 4: 0.8894 | 「おお、今日で最後だってね。寂しくなるよ...\n",
      "ID 5: 0.9406 | 「こちらこそ、お世話になりました」...\n",
      "ID 6: 0.2858 | 林さんは私の前にコーヒーを置いた。「三十...\n",
      "ID 7: 0.9165 | 「あっという間でした」...\n",
      "ID 8: 0.7075 | 「嘘つけ。いろんなことがあっただろう」...\n",
      "ID 9: 0.1720 | 確かに、林さんの言う通りだ。この三十年、...\n",
      "ID 10: 0.2170 | 十年前、一人息子が大学に合格した。その合...\n",
      "ID 11: 0.3827 | 五年前、妻が病気で倒れた。入院中、私は毎...\n",
      "ID 12: 0.6657 | ポストに手紙を入れながら、私は思い出して...\n",
      "ID 13: 0.1365 | 結婚式の招待状を届けた家族が、数年後に出...\n",
      "ID 14: 0.5222 | 配達を終えて郵便局に戻ろうとしたとき、カ...\n",
      "ID 15: 0.5895 | 差出人の欄を見ると、「藤原健一」という名...\n",
      "ID 16: 0.8443 | 「宛先不明で返送するしかないですね」と若...\n",
      "ID 17: 0.7280 | 「少し調べてみます」と私は言った。同僚は...\n",
      "ID 18: 0.3859 | 退職する私に、これ以上の仕事を押し付ける...\n",
      "ID 19: 0.2040 | 私は古い配達記録を調べ始めた。郵便局の倉...\n",
      "ID 20: 0.6336 | 私はアパートを訪ねた。管理人室のドアをノ...\n",
      "ID 21: 0.7216 | 「白石さんねえ……ああ、思い出した。確か...\n",
      "ID 22: 0.7751 | 「何か、手がかりはありませんか？彼女のこ...\n",
      "ID 23: 0.7984 | 管理人は少し考えてから言った。「そういえ...\n",
      "ID 24: 0.2645 | 私は礼を言って三階に上がった。階段を上り...\n",
      "ID 25: 0.2326 | 出てきたのは、六十代くらいの女性だった。...\n",
      "ID 26: 0.8095 | 「すみません、郵便局の者ですが、白石幸子...\n",
      "ID 27: 0.7264 | 鈴木さんは一瞬驚いた表情を見せたが、すぐ...\n",
      "ID 28: 0.1457 | 部屋に案内され、ソファに座る。鈴木さんは...\n",
      "ID 29: 0.5722 | 「あの人、元気にしているのかしら」と鈴木...\n",
      "ID 30: 0.9464 | 「実は、彼女宛の手紙が届いていまして、転...\n",
      "ID 31: 0.2807 | 鈴木さんは窓の外を見つめながら、ゆっくり...\n",
      "ID 32: 0.4676 | 「幸子さんとは、このアパートで十年以上隣...\n",
      "ID 33: 0.3890 | 鈴木さんは少し表情を曇らせた。...\n",
      "ID 34: 0.7522 | 「でも、いつも少し寂しそうな影があったん...\n",
      "ID 35: 0.8398 | 「それが変わったのは、十六年前の春でした...\n",
      "ID 36: 0.8253 | 「寂しそう、ですか」...\n",
      "ID 37: 0.5959 | 「ええ。彼女には恋人がいたんです。藤原さ...\n",
      "ID 38: 0.6250 | 私は驚いた。藤原という名前は、この手紙の...\n",
      "ID 39: 0.4364 | 鈴木さんは続けた。「ある日、幸子さんが嬉...\n",
      "ID 40: 0.3513 | 鈴木さんの目に涙が浮かんだ。...\n",
      "ID 41: 0.8397 | 「でも、それから数ヶ月後、藤原さんが来な...\n",
      "ID 42: 0.7792 | 「何があったんでしょうか」...\n",
      "ID 43: 0.6409 | 「わかりません。幸子さんは何も教えてくれ...\n",
      "ID 44: 0.6884 | 「そして半年後、幸子さんは引っ越していき...\n",
      "ID 45: 0.6745 | 「転居先は？」...\n",
      "ID 46: 0.7470 | 「教えてくれませんでした。『連絡は自分か...\n",
      "ID 47: 0.5199 | 鈴木さんは涙を拭いた。「あの人、今も一人...\n",
      "ID 48: 0.5521 | 私は考え込んだ。藤原さんと白石さんに、何...\n",
      "ID 49: 0.5615 | 「ありがとうございました」と言って立ち上...\n",
      "ID 50: 0.9205 | 「あの、もしかしたら、幸子さんの実家の住...\n",
      "ID 51: 0.5535 | 鈴木さんは本棚から古いノートを取り出し、...\n",
      "ID 52: 0.5609 | 「ここです。確か、北海道の函館だったと思...\n",
      "ID 53: 0.8981 | 私は深く頭を下げた。「本当にありがとうご...\n",
      "ID 54: 0.6676 | 鈴木さんは私の手を握った。「お願いします...\n",
      "ID 55: 0.5781 | 郵便局に戻ると、私は上司に事情を説明した...\n",
      "ID 56: 0.3546 | 上司は眉をひそめた。「でも、函館は遠いで...\n",
      "ID 57: 0.8424 | 「わかっています。でも、この手紙には特別...\n",
      "ID 58: 0.5237 | 上司は少し困った顔をしたが、やがて頷いた...\n",
      "ID 59: 0.5741 | 「ありがとうございます」...\n",
      "ID 60: 0.3745 | 私は笑顔で頷いた。家に帰って妻に事情を話...\n",
      "ID 61: 0.7865 | 「あなたらしいわね。でも、無理はしないで...\n",
      "ID 62: 0.6938 | 「大丈夫だよ」...\n",
      "ID 63: 0.5991 | 「本当に？あなた、もう六十歳なのよ」...\n",
      "ID 64: 0.4387 | 「まだまだ若いさ」...\n",
      "ID 65: 0.4687 | 妻は笑った。「行ってらっしゃい。気をつけ...\n",
      "ID 66: 0.7166 | 翌日、私は函館行きの飛行機に乗った。窓か...\n",
      "ID 67: 0.2373 | 函館空港に着くと、タクシーで鈴木さんから...\n",
      "ID 68: 0.3963 | 「ここです」と運転手が言った。...\n",
      "ID 69: 0.0997 | 降りると、目の前に古い日本家屋が建ってい...\n",
      "ID 70: 0.5175 | 深呼吸をして、ドアをノックした。しばらく...\n",
      "ID 71: 0.5454 | 「はい、どちら様でしょうか」...\n",
      "ID 72: 0.7287 | 「東京の郵便局で働いていた者です。白石幸...\n",
      "ID 73: 0.2741 | 女性は驚いた表情を見せた。目が大きく見開...\n",
      "ID 74: 0.6704 | 「幸子は私の娘です。でも、娘は今、市内の...\n",
      "ID 75: 0.3454 | 私の胸に不安が走った。「病院、ですか」...\n",
      "ID 76: 0.7018 | 「ええ。半年前から体調を崩して。医者から...\n",
      "ID 77: 0.7678 | 私は手に持っていた手紙を見せた。「実は、...\n",
      "ID 78: 0.8346 | 女性の顔色が変わった。「藤原さん……あの...\n",
      "ID 79: 0.5985 | 「ご存じなんですか？」...\n",
      "ID 80: 0.5128 | 女性は頷いた。「娘から、話は聞いています...\n",
      "ID 81: 0.6869 | 「差し支えなければ、病院を教えていただけ...\n",
      "ID 82: 0.8237 | 女性は複雑な表情を浮かべたが、やがて病院...\n",
      "ID 83: 0.7344 | 「すぐに伺います」...\n",
      "ID 84: 0.7865 | 「待ってください」と女性が言った。「娘に...\n",
      "ID 85: 0.4205 | 「もちろんです」...\n",
      "ID 86: 0.7042 | 女性は涙を浮かべた。「ありがとうございま...\n",
      "ID 87: 0.3287 | 一時間後、私は病院に向かった。函館市内の...\n",
      "ID 88: 0.7411 | 病室の扉の前で、看護師が言った。「白石さ...\n",
      "ID 89: 0.6684 | 「わかりました」...\n",
      "ID 90: 0.2745 | 扉を開けると、窓際のベッドに横たわる痩せ...\n",
      "ID 91: 0.7411 | 「どちら様ですか？」と弱々しい声で聞いた...\n",
      "ID 92: 0.7676 | 「郵便局の者です。あなた宛の手紙を届けに...\n",
      "ID 93: 0.6207 | 私が手紙を取り出すと、彼女の目が大きく見...\n",
      "ID 94: 0.8763 | 「健一さん……」...\n",
      "ID 95: 0.6170 | 声が震えている。彼女は震える手で手紙を受...\n",
      "ID 96: 0.7203 | 「ありがとうございます」と彼女は涙声で言...\n",
      "ID 97: 0.2712 | 彼女は震える手で封を開けようとしたが、う...\n",
      "ID 98: 0.8248 | 「自分で開けたいんです。健一さんからの、...\n",
      "ID 99: 0.3380 | ゆっくりと、時間をかけて、彼女は封を開け...\n",
      "ID 100: 0.8417 | 「ごめんなさい。涙で、字が見えなくて」...\n",
      "ID 101: 0.3924 | 私は静かに部屋を出ようとしたが、彼女が声...\n",
      "ID 102: 0.8449 | 「待ってください。読んでもらえますか？目...\n",
      "ID 103: 0.4775 | 私は頷き、彼女から便箋を受け取った。そし...\n",
      "ID 104: 0.8520 | 「幸子へ。十五年ぶりに手紙を書いています...\n",
      "ID 105: 0.2574 | あの日、僕が突然姿を消したこと、許してほ...\n",
      "ID 106: 0.3526 | 君と結婚の約束をしていたのに、こんな体で...\n",
      "ID 107: 0.3779 | だから、僕は何も言わずに去りました。君を...\n",
      "ID 108: 0.2458 | それから十五年。僕はまだ生きています。医...\n",
      "ID 109: 0.2504 | その間、一日として君のことを忘れた日はあ...\n",
      "ID 110: 0.4344 | でも、もう調べることもできませんでした。...\n",
      "ID 111: 0.6660 | 今、僕は老人ホームにいます。体はもう動き...\n",
      "ID 112: 0.5398 | 幸子、僕は臆病者でした。君を愛していると...\n",
      "ID 113: 0.4827 | 君の幸せを心から願っています。健一」...\n",
      "ID 114: 0.5051 | 私が読み終えると、幸子さんは静かに泣いて...\n",
      "ID 115: 1.0000 | 「馬鹿ね、健一さん……私、ずっと待ってい...\n",
      "ID 116: 0.0983 | 彼女は天井を見つめながら続けた。...\n",
      "ID 117: 0.9490 | 「私、健一さんがいなくなってから、ずっと...\n",
      "ID 118: 0.6147 | 「だから、函館に戻ったんです。実家に戻っ...\n",
      "ID 119: 0.7482 | 「会いに行きたいですか？」と私は聞いた。...\n",
      "ID 120: 0.5333 | 彼女は驚いた表情で私を見た。「でも、もう...\n",
      "ID 121: 0.6265 | 「大丈夫です。私が連れて行きます。医者に...\n",
      "ID 122: 0.8044 | 幸子さんの目に、希望の光が灯った。「本当...\n",
      "ID 123: 0.4793 | 「はい。必ず」...\n",
      "ID 124: 0.3185 | 私は医師を呼び、事情を説明した。医師は難...\n",
      "ID 125: 0.2389 | 「白石さんの容態は安定していません。移動...\n",
      "ID 126: 0.4230 | 「でも、これが最後のチャンスかもしれない...\n",
      "ID 127: 0.3712 | 医師は考え込んだ。そして、看護師と相談し...\n",
      "ID 128: 0.3835 | 「わかりました。救急車を手配します。ただ...\n",
      "ID 129: 0.4205 | 「もちろんです」...\n",
      "ID 130: 0.6138 | 翌日、幸子さんを乗せた救急車が函館を出発...\n",
      "ID 131: 0.8728 | 「ありがとうございます」と幸子さんが言っ...\n",
      "ID 132: 0.7689 | 「田村といいます」...\n",
      "ID 133: 0.7205 | 「田村さん、あなたは天使のような人ですね...\n",
      "ID 134: 0.5958 | 「いえ、私はただの郵便配達員です」...\n",
      "ID 135: 0.7446 | 「でも、あなたは私の人生を変えてくれまし...\n",
      "ID 136: 0.1710 | 函館から東京までは遠い。飛行機を使っても...\n",
      "ID 137: 0.5012 | 途中、何度も休憩を取った。幸子さんは疲れ...\n",
      "ID 138: 0.2087 | 二日がかりで、私たちは東京に着いた。藤原...\n",
      "ID 139: 0.3438 | 受付で事情を説明すると、職員が驚いた表情...\n",
      "ID 140: 0.9410 | 「藤原さんですか？あの方、最近ずっと元気...\n",
      "ID 141: 0.7913 | 職員は私たちを藤原さんの部屋に案内してく...\n",
      "ID 142: 0.3439 | 部屋の前で、職員がノックした。...\n",
      "ID 143: 0.8959 | 「藤原さん、お客様です」...\n",
      "ID 144: 0.7023 | 中から弱々しい声がした。「誰だい？」...\n",
      "ID 145: 0.6682 | 「特別な方です」...\n",
      "ID 146: 0.2778 | 扉を開けると、車椅子に座った痩せた老人が...\n",
      "ID 147: 0.5193 | 「藤原さん」と職員が声をかけると、彼はゆ...\n",
      "ID 148: 0.4016 | そして、救急車のストレッチャーに横たわる...\n",
      "ID 149: 0.7276 | 「幸子……」...\n",
      "ID 150: 0.8213 | 「健一さん」...\n",
      "ID 151: 0.4512 | 二人は言葉を失い、ただ見つめ合った。私と...\n",
      "ID 152: 0.4962 | 廊下で待っていると、部屋から声が聞こえて...\n",
      "ID 153: 0.3406 | 「お二人とも、とても幸せそうです。ありが...\n",
      "ID 154: 0.5174 | 私は頷いた。これが、私にできる最後の配達...\n",
      "ID 155: 0.3962 | 数日後、私は東京に戻った。そして一週間後...\n",
      "ID 156: 0.7591 | 「藤原さんが亡くなりました。最後まで、幸...\n",
      "ID 157: 0.4255 | そして、その二日後、幸子さんも息を引き取...\n",
      "ID 158: 0.5436 | 私は二人の葬儀に参列した。遺族の方から聞...\n",
      "ID 159: 0.4337 | 葬儀の後、幸子さんの母親が私に言った。...\n",
      "ID 160: 0.8715 | 「あなたが手紙を届けてくれなければ、娘は...\n",
      "ID 161: 0.5872 | 私は頭を下げた。「いえ、これが私の仕事で...\n",
      "ID 162: 0.4813 | 帰りの電車の中で、私は思った。三十年間、...\n",
      "ID 163: 0.6871 | 先輩が言った言葉の意味が、今ならわかる。...\n",
      "ID 164: 0.1606 | 定年退職して、何もすることがないと思って...\n",
      "ID 165: 0.2355 | 翌週、私はボランティアセンターを訪ねた。...\n",
      "ID 166: 0.4829 | 受付の女性は笑顔で言った。「ちょうど、そ...\n",
      "ID 167: 0.1410 | 私の第二の人生が、そこから始まった。まだ...\n",
      "ID 168: 0.2106 | 私は歩き続ける。誰かの想いを運ぶために。...\n",
      "ID 169: 0.8119 | \"\"\"...\n",
      "\n",
      "--- 検索テスト: 'GEM-RAGの仕組みは？' ---\n",
      "Score: 0.5841 (Sim: 0.08, Eigen: 0.92)\n",
      "Content: 「あの、もしかしたら、幸子さんの実家の住所がわかるかもしれません。昔、年賀状の宛名を見せてもらったことがあって。確か、ノートにメモしたような気がします」\n",
      "--------------------\n",
      "Score: 0.5820 (Sim: 0.04, Eigen: 0.95)\n",
      "Content: 「実は、彼女宛の手紙が届いていまして、転居先がわからないのです。何か、ご存じないでしょうか」\n",
      "--------------------\n",
      "Score: 0.5771 (Sim: 0.02, Eigen: 0.95)\n",
      "Content: 「私、健一さんがいなくなってから、ずっと考えていたんです。何が悪かったんだろうって。私の何かが、彼を遠ざけたんだろうかって。でも、理由がわからなくて、苦しくて。東京にいると、健一さんとの思い出ばかりが蘇ってきて、前に進めなくて」\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. テキストファイルを読み込む\n",
    "with open(\"story.txt\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "# 段落ごとに分割（「空行」で区切る想定）\n",
    "raw = text.split(\"\\n\\n\")\n",
    "docs = [p.strip() for p in raw if p.strip()]\n",
    "\n",
    "# 2. エンジン準備\n",
    "model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "engine = GemRagEngine(model)\n",
    "\n",
    "# 3. インデックス作成\n",
    "engine.ingest(docs, similarity_threshold=0.3)\n",
    "\n",
    "print(\"\\n--- 各チャンクの固有値スコア (情報の重要度) ---\")\n",
    "for i, score in enumerate(engine.eigen_scores):\n",
    "    print(f\"ID {i}: {score:.4f} | {docs[i][:20]}...\")\n",
    "\n",
    "print(\"\\n--- 検索テスト: 'GEM-RAGの仕組みは？' ---\")\n",
    "results = engine.search(\"GEM-RAGの仕組みは？\", top_k=3, alpha=0.4)\n",
    "for res in results:\n",
    "    print(f\"Score: {res['score']:.4f} (Sim: {res['similarity']:.2f}, Eigen: {res['eigen_score']:.2f})\")\n",
    "    print(f\"Content: {res['chunk']}\")\n",
    "    print(\"-\" * 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
